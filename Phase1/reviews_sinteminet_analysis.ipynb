{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## web scraping on Reviews URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [\"ID\",\"Reviews\"])\n",
    "# Read CSV file\n",
    "# with open('games-regression-dataset.csv', newline='') as csvfile:\n",
    "with open('games-regression-dataset.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)  # Skip header row\n",
    "    for row in reader:\n",
    "        url = row[0]  # URL is in first column\n",
    "        filename = 'Reviews/'+os.path.basename(url)  # Extract filename from URL\n",
    "        url +=  \"?see-all=reviews\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:  # Check if request was successful\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            blocks = soup.findAll(\"blockquote\")\n",
    "            review_list = []\n",
    "            for blockquote in blocks:\n",
    "                review = blockquote.find('p').text\n",
    "                review_list.append(review)\n",
    "            if len(review_list)!=0:\n",
    "                filename = re.sub(r'[^\\d]+', '', filename)\n",
    "                new_row = {'ID': filename,\"Reviews\": review_list}\n",
    "                df = df._append(new_row, ignore_index=True)\n",
    "df.to_csv('Reviews.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Reviews.csv')\n",
    "counter=0\n",
    "\n",
    "for i in range (len(data)):\n",
    "    data.at[i, 'Reviews'] = data.at[i, \"Reviews\"].split(\"',\")\n",
    "    data.at[i,\"ID\"] =data.at[i,\"ID\"]\n",
    "data = data.explode('Reviews')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert text to lowercase\n",
    "data['Reviews'] = data['Reviews'].apply(lambda x: str(x).lower())\n",
    "\n",
    "# Replace newline characters with an empty string\n",
    "data['Reviews'] = data['Reviews'].apply(lambda x: re.sub(r'\\\\n', ' ', x))\n",
    "\n",
    "# Remove black squares\n",
    "data['Reviews'] = data['Reviews'].apply(lambda x: re.sub(r'\\\\u25a0', '', x))\n",
    "\n",
    "# Remove special characters and punctuations\n",
    "data['Reviews'] = data['Reviews'].apply(lambda x: re.sub(r'[^\\w\\s]+', '', x))\n",
    "\n",
    "# Remove numbers\n",
    "data['Reviews'] = data['Reviews'].apply(lambda x: \" \".join([word for word in x.split() if not any(char.isdigit() for char in word)]))\n",
    "\n",
    "# Remove extra whitespaces\n",
    "data['Reviews'] = data['Reviews'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "\n",
    "# Remove stop words\n",
    "data['Reviews'] = data['Reviews'].apply(lambda x: \" \".join([word for word in x.lower().split() if word not in stop_words]))\n",
    "\n",
    "# Remove empty strings\n",
    "data = data[data['Reviews'].apply(lambda x: len(x)>0)]\n",
    "\n",
    "data.at[0,'Reviews']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vader-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia_reviews = SentimentIntensityAnalyzer()\n",
    "# pickle.dump(sia_reviews, open('encoders/sia_reviews.pkl', 'wb'))\n",
    "data['Reviews'] = data['Reviews'].apply(lambda x: dict(sia_reviews.polarity_scores(x))['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get compound average & Group by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.groupby('ID')['Reviews'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lowest, highest and average purchase\n",
    "data['lowest_review'] = data['Reviews'].apply(lambda x: min(x) if len(x) > 0 else 0)\n",
    "data['highest_review'] = data['Reviews'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "data['average_review'] = data['Reviews'].apply(lambda x: np.mean(x) if len(x) > 0 else 0)\n",
    "data = data.drop(['Reviews'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('reviews_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
