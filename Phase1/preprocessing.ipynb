{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T14:19:38.839351Z",
     "start_time": "2023-04-14T14:19:38.815268Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:33:46.390000Z",
     "start_time": "2023-04-14T10:33:46.279076Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('games-regression-dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:07.218975Z",
     "start_time": "2023-04-14T10:35:07.199405Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop Primary Genre\n",
    "df.drop(['Primary Genre', 'ID', 'URL', 'Icon URL'], axis=1, inplace=True)\n",
    "\n",
    "df['Original Release Date'] = pd.to_datetime(df['Original Release Date'], format='%d/%m/%Y')\n",
    "df['Current Version Release Date'] = pd.to_datetime(df['Current Version Release Date'], format='%d/%m/%Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T16:07:00.183708Z",
     "start_time": "2023-04-13T16:07:00.127616Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:05.138536Z",
     "start_time": "2023-04-13T14:33:05.138536Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:07.893814Z",
     "start_time": "2023-04-13T14:33:07.893814Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:21.139604Z",
     "start_time": "2023-04-13T14:33:21.139604Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genres\n",
       "Strategy               5214\n",
       "Games                  5214\n",
       "Entertainment          2674\n",
       "Puzzle                  991\n",
       "Simulation              796\n",
       "Action                  711\n",
       "Board                   625\n",
       "Role Playing            556\n",
       "Casual                  344\n",
       "Card                    251\n",
       "Adventure               240\n",
       "Family                  213\n",
       "Education               196\n",
       "Sports                  190\n",
       "Trivia                   61\n",
       "Lifestyle                55\n",
       "Utilities                53\n",
       "Social Networking        45\n",
       "Music                    34\n",
       "Reference                32\n",
       "Racing                   32\n",
       "Word                     30\n",
       "Travel                   29\n",
       "Casino                   23\n",
       "Finance                  18\n",
       "Food & Drink             17\n",
       "Productivity             15\n",
       "Health & Fitness         13\n",
       "Books                    10\n",
       "News                      9\n",
       "Business                  8\n",
       "Photo & Video             6\n",
       "Medical                   3\n",
       "Stickers                  2\n",
       "Gaming                    2\n",
       "Navigation                2\n",
       "Shopping                  1\n",
       "Emoji & Expressions       1\n",
       "Kids & Family             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genres'] = df['Genres'].astype(str)\n",
    "df['Genres'] = df['Genres'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "genre_counts = df.explode('Genres').groupby('Genres').size().sort_values(ascending=False)\n",
    "genre_counts\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:43.637371Z",
     "start_time": "2023-04-13T14:33:43.637371Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Developer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:47.598084Z",
     "start_time": "2023-04-13T14:33:47.598084Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Developer'].unique().size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:49.943309Z",
     "start_time": "2023-04-13T14:33:49.943309Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages\n",
      "ZH    1880\n",
      "DE    1127\n",
      "FR    1078\n",
      "ES    1049\n",
      "JA     976\n",
      "RU     936\n",
      "IT     869\n",
      "KO     810\n",
      "PT     809\n",
      "TR     489\n",
      "NL     474\n",
      "PL     425\n",
      "SV     382\n",
      "TH     277\n",
      "DA     276\n",
      "CS     272\n",
      "ID     259\n",
      "NB     248\n",
      "FI     238\n",
      "EL     231\n",
      "VI     217\n",
      "AR     205\n",
      "HE     187\n",
      "MS     182\n",
      "HU     182\n",
      "SK     169\n",
      "RO     169\n",
      "CA     145\n",
      "UK     137\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Languages'] = df['Languages'].astype(str)\n",
    "\n",
    "df['Languages'] = df['Languages'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "langs_counts = df.explode('Languages').groupby('Languages').size().sort_values(ascending=False)\n",
    "print(langs_counts[1:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Developer preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:14.110217Z",
     "start_time": "2023-04-14T10:35:13.123201Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "df['Developer'] = df['Developer'].astype(str)\n",
    "df['Developer'] = df['Developer'].str.replace(\"'\", \"\").str.strip('[]')\n",
    "\n",
    "dev_counts = df['Developer'].value_counts()\n",
    "other = dev_counts[dev_counts < 5].index\n",
    "df['Developer'] = df['Developer'].replace(other, 'Other')\n",
    "\n",
    "dev_df = df[['Developer', 'Average User Rating']].groupby('Developer').mean()\n",
    "dev_df['Count'] = df['Developer'].value_counts()\n",
    "\n",
    "dev_df = dev_df.sort_values(by='Count', ascending=False)\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:16.888246Z",
     "start_time": "2023-04-14T10:35:16.822234Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace the developer names with the average user rating from dev_df\n",
    "df['Developer'] = df['Developer'].replace(dev_df.index, dev_df['Average User Rating'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Genres preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. NLP approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:21.245168Z",
     "start_time": "2023-04-14T10:35:20.885068Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Convert the genres column to a list of strings\n",
    "df['Genres'] = df['Genres'].astype(str)\n",
    "df['Genres'] = df['Genres'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# drop Games, Strategy, Entertainment from the Genres column\n",
    "df['Genres'] = df['Genres'].apply(lambda x: [genre for genre in x if genre not in ['Games', 'Strategy', 'Entertainment']])\n",
    "\n",
    "# Join the list of genres into a single string\n",
    "genres = df['Genres'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Create a count Vectorizer and fit it to the genres\n",
    "count_vec = CountVectorizer()\n",
    "bow_genres = count_vec.fit_transform(genres)\n",
    "\n",
    "# Apply principal component analysis to reduce the dimensionality\n",
    "pca = PCA(n_components=10)\n",
    "pca_genres = pca.fit_transform(bow_genres.toarray())\n",
    "\n",
    "# Add the PCA-transformed genres to the original dataframe\n",
    "for i in range(len(pca_genres[0])):\n",
    "    df[f'Genre_PCA_{i}'] = pca_genres[:, i]\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Genres'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dummy variables approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Version Release Date</th>\n",
       "      <th>Average User Rating</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Board</th>\n",
       "      <th>Card</th>\n",
       "      <th>Casual</th>\n",
       "      <th>Education</th>\n",
       "      <th>Family</th>\n",
       "      <th>Puzzle</th>\n",
       "      <th>Role Playing</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>Sports</th>\n",
       "      <th>infrequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/07/2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/06/2017</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21/04/2015</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/2/2019</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Current Version Release Date  Average User Rating  Action  Adventure  Board  \\\n",
       "0                   31/07/2019                  4.0       0          0      0   \n",
       "1                   28/06/2017                  3.5       0          0      0   \n",
       "2                   21/04/2015                  4.5       0          0      0   \n",
       "3                   23/07/2019                  3.5       0          0      0   \n",
       "4                     6/2/2019                  4.5       0          0      0   \n",
       "\n",
       "   Card  Casual  Education  Family  Puzzle  Role Playing  Simulation  Sports  \\\n",
       "0     0       0          0       0       0             1           0       0   \n",
       "1     0       0          0       0       0             0           1       0   \n",
       "2     1       0          0       0       0             0           0       0   \n",
       "3     1       0          0       0       0             0           0       0   \n",
       "4     0       0          0       0       0             1           0       0   \n",
       "\n",
       "   infrequent  \n",
       "0           0  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Convert the genres column to a list of strings\n",
    "df['Genres'] = df['Genres'].astype(str)\n",
    "df['Genres'] = df['Genres'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# drop Games, Strategy, Entertainment from the Genres column\n",
    "df['Genres'] = df['Genres'].apply(lambda x: [genre for genre in x if genre not in ['Games', 'Strategy', 'Entertainment']])\n",
    "\n",
    "# Replace genres with counts less than 100 with 'infrequent' as it would represent a very small percentage of the data (less than 2%)\n",
    "other = df['Genres'].explode().value_counts()[df['Genres'].explode().value_counts() < 100].index\n",
    "df['Genres'] = df['Genres'].apply(lambda x: [genre if genre not in other else 'infrequent' for genre in x])\n",
    "\n",
    "# Replace empty lists with 'infrequent'\n",
    "df['Genres'] = df['Genres'].apply(lambda x: ['infrequent'] if len(x) == 0 else x)\n",
    "\n",
    "# Get dummy variables for the genres\n",
    "genres = pd.get_dummies(df['Genres'].apply(pd.Series).stack()).sum(level=0)\n",
    "\n",
    "# Add the dummy variables to the original dataframe\n",
    "df = pd.concat([df, genres], axis=1)\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Genres'], axis=1)\n",
    "\n",
    "df.iloc[:, 15:].head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multi-label binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5214, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Version Release Date</th>\n",
       "      <th>Average User Rating</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Board</th>\n",
       "      <th>Card</th>\n",
       "      <th>Casual</th>\n",
       "      <th>Education</th>\n",
       "      <th>Family</th>\n",
       "      <th>Puzzle</th>\n",
       "      <th>Role Playing</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>Sports</th>\n",
       "      <th>infrequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/07/2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/06/2017</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21/04/2015</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/2/2019</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Current Version Release Date  Average User Rating  Action  Adventure  Board  \\\n",
       "0                   31/07/2019                  4.0       0          0      0   \n",
       "1                   28/06/2017                  3.5       0          0      0   \n",
       "2                   21/04/2015                  4.5       0          0      0   \n",
       "3                   23/07/2019                  3.5       0          0      0   \n",
       "4                     6/2/2019                  4.5       0          0      0   \n",
       "\n",
       "   Card  Casual  Education  Family  Puzzle  Role Playing  Simulation  Sports  \\\n",
       "0     0       0          0       0       0             1           0       0   \n",
       "1     0       0          0       0       0             0           1       0   \n",
       "2     1       0          0       0       0             0           0       0   \n",
       "3     1       0          0       0       0             0           0       0   \n",
       "4     0       0          0       0       0             1           0       0   \n",
       "\n",
       "   infrequent  \n",
       "0           0  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Convert the genres column to a list of strings\n",
    "df['Genres'] = df['Genres'].astype(str)\n",
    "df['Genres'] = df['Genres'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# drop Games, Strategy, Entertainment from the Genres column\n",
    "df['Genres'] = df['Genres'].apply(lambda x: [genre for genre in x if genre not in ['Games', 'Strategy', 'Entertainment']])\n",
    "\n",
    "# Replace genres with counts less than 100 with 'infrequent' as it would represent a very small percentage of the data (less than 2%)\n",
    "other = df['Genres'].explode().value_counts()[df['Genres'].explode().value_counts() < 100].index\n",
    "df['Genres'] = df['Genres'].apply(lambda x: [genre if genre not in other else 'infrequent' for genre in x])\n",
    "\n",
    "# Replace empty lists with 'infrequent'\n",
    "df['Genres'] = df['Genres'].apply(lambda x: ['infrequent'] if len(x) == 0 else x)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit the MultiLabelBinarizer to the genres\n",
    "mlb.fit(df['Genres'])\n",
    "\n",
    "# Save the mlb for later use with the test data\n",
    "pickle.dump(mlb, open('mlb.pkl', 'wb'))\n",
    "\n",
    "# Transform the genres into a one-hot encoded array\n",
    "genres_mlb = mlb.transform(df['Genres'])\n",
    "\n",
    "# Create a dataframe from the one-hot encoded array\n",
    "genres_mlb_df = pd.DataFrame(genres_mlb, columns=mlb.classes_)\n",
    "\n",
    "# Add the one-hot encoded genres to the original dataframe\n",
    "df = pd.concat([df, genres_mlb_df], axis=1)\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Genres'], axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.iloc[:, 15:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Languages preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. NLP approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:38.695352Z",
     "start_time": "2023-04-14T10:35:38.599717Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the genres column to a list of strings\n",
    "df['Languages'] = df['Languages'].astype(str)\n",
    "df['Languages'] = df['Languages'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# drop Games, Strategy, Entertainment from the Genres column\n",
    "df['Languages'] = df['Languages'].apply(lambda x: [lang for lang in x if lang not in ['En']])\n",
    "\n",
    "# Join the list of genres into a single string\n",
    "languages = df['Languages'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Create a count Vectorizer and fit it to the genres\n",
    "count_vec = CountVectorizer()\n",
    "bow_languages = count_vec.fit_transform(languages)\n",
    "\n",
    "# Apply principal component analysis to reduce the dimensionality\n",
    "pca = PCA(n_components=10)\n",
    "pca_languages = pca.fit_transform(bow_languages.toarray())\n",
    "\n",
    "# Add the PCA-transformed genres to the original dataframe\n",
    "for i in range(10):\n",
    "    df[f'Languages_PCA_{i}'] = pca_languages[:, i]\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Languages'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multi-label binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Convert the genres column to a list of strings\n",
    "df['Languages'] = df['Languages'].astype(str)\n",
    "df['Languages'] = df['Languages'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# drop Games, Strategy, Entertainment from the Genres column\n",
    "df['Languages'] = df['Languages'].apply(lambda x: [genre for genre in x if genre not in ['Games', 'Strategy', 'Entertainment']])\n",
    "\n",
    "# Replace genres with counts less than 100 with 'infrequent' as it would represent a very small percentage of the data (less than 2%)\n",
    "other = df['Languages'].explode().value_counts()[df['Genres'].explode().value_counts() < 100].index\n",
    "df['Languages'] = df['Languages'].apply(lambda x: [genre if genre not in other else 'infrequent' for genre in x])\n",
    "\n",
    "# Replace empty lists with 'infrequent'\n",
    "df['Languages'] = df['Languages'].apply(lambda x: ['infrequent'] if len(x) == 0 else x)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit the MultiLabelBinarizer to the genres\n",
    "mlb.fit(df['Languages'])\n",
    "\n",
    "# Save the mlb for later use with the test data\n",
    "pickle.dump(mlb, open('mlb.pkl', 'wb'))\n",
    "\n",
    "# Transform the genres into a one-hot encoded array\n",
    "genres_mlb = mlb.transform(df['Languages'])\n",
    "\n",
    "# Create a dataframe from the one-hot encoded array\n",
    "genres_mlb_df = pd.DataFrame(genres_mlb, columns=mlb.classes_)\n",
    "\n",
    "# Add the one-hot encoded genres to the original dataframe\n",
    "df = pd.concat([df, genres_mlb_df], axis=1)\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Languages'], axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.iloc[:, 15:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## In-app Purchases preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:52.935497Z",
     "start_time": "2023-04-14T10:35:52.881403Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Free apps might skew the in-app purchases column,\n",
    "# so we might split the dataset into free and paid apps\n",
    "\n",
    "df['In-app Purchases'] = df['In-app Purchases'].astype(str)\n",
    "df['In-app Purchases'] = df['In-app Purchases'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:54.565885Z",
     "start_time": "2023-04-14T10:35:54.456681Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to float\n",
    "df['In-app Purchases'] = df['In-app Purchases'].apply(lambda x: [float(i) for i in x])\n",
    "\n",
    "# Get the lowest, highest and average purchase\n",
    "df['Lowest Purchase'] = df['In-app Purchases'].apply(lambda x: min(x) if len(x) > 0 else 0)\n",
    "df['Highest Purchase'] = df['In-app Purchases'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "df['Average Purchase'] = df['In-app Purchases'].apply(lambda x: np.mean(x) if len(x) > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:36:00.624093Z",
     "start_time": "2023-04-14T10:36:00.576764Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop the original column\n",
    "df = df.drop(['In-app Purchases'], axis=1)\n",
    "\n",
    "df['Lowest Purchase'] = df['Lowest Purchase'].fillna(0)\n",
    "df['Highest Purchase'] = df['Highest Purchase'].fillna(0)\n",
    "df['Average Purchase'] = df['Average Purchase'].fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Age Rating preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:36:03.614263Z",
     "start_time": "2023-04-14T10:36:03.579637Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "df['Age Rating'] = df['Age Rating'].astype(str)\n",
    "\n",
    "# Remove the + sign\n",
    "df['Age Rating'] = df['Age Rating'].str.replace('+', '')\n",
    "\n",
    "# Convert to int\n",
    "df['Age Rating'] = df['Age Rating'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dates preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:36:05.737187Z",
     "start_time": "2023-04-14T10:36:05.699973Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the datetime to ordinal\n",
    "df['Original Release Date'] = df['Original Release Date'].apply(lambda x: x.toordinal())\n",
    "df['Current Version Release Date'] = df['Current Version Release Date'].apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:43:13.386866Z",
     "start_time": "2023-04-14T10:43:13.386866Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def preprocess_nlp(col):\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "    # Remove URLs and email addresses\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'http\\S+|www.\\S+|\\S+@\\S+', '', x))\n",
    "\n",
    "    # Remove the punctuation, numbers, and convert to lowercase\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(re.findall(r'\\w+', x.lower())))\n",
    "\n",
    "    # Remove the stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "    # Stemming\n",
    "    st = nltk.PorterStemmer()\n",
    "    df[col] = df[col].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "\n",
    "    # Lemmatization\n",
    "    lem = nltk.WordNetLemmatizer()\n",
    "    df[col] = df[col].apply(lambda x: \" \".join([lem.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "    # Remove the frequent and rare words\n",
    "    freq = pd.Series(' '.join(df[col]).split()).value_counts()\n",
    "    common_freq = list(freq[:10].index)\n",
    "    rare_freq = list(freq[-10:].index)\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x for x in x.split() if x not in common_freq+rare_freq))\n",
    "\n",
    "    # Remove the whitespaces\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x.strip() for x in x.split()))\n",
    "\n",
    "    # Replace NaN values with empty string\n",
    "    df[col] = df[col].fillna('')\n",
    "\n",
    "    # Convert text data to bag-of-words representation\n",
    "    vectorizer = CountVectorizer()\n",
    "    BoW = vectorizer.fit_transform(df[col])\n",
    "\n",
    "    # Apply principal component analysis to reduce the dimensionality\n",
    "    pca_ = PCA(n_components=10)\n",
    "    pca_col = pca_.fit_transform(BoW.toarray())\n",
    "\n",
    "    # Add the PCA-transformed col to the original dataframe\n",
    "    for feat in range(10):\n",
    "        df[f'{col}_PCA_{feat}'] = pca_col[:, feat]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:43:49.505557Z",
     "start_time": "2023-04-14T10:43:49.505557Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_nlp('Description')\n",
    "preprocess_nlp('Subtitle')\n",
    "preprocess_nlp('Name')\n",
    "\n",
    "df = df.drop(['Description', 'Subtitle', 'Name'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Icon preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Download the icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T15:23:14.248477Z",
     "start_time": "2023-04-13T15:23:14.247478Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "df['Icon URL'] = df['Icon URL'].astype(str)\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "def download_image(url, filename):\n",
    "    r = requests.get(url, stream=True)\n",
    "    if r.status_code == 200:\n",
    "        with open(filename, 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "\n",
    "# Create a folder to store the images\n",
    "if not os.path.exists('icons'):\n",
    "    os.makedirs('icons')\n",
    "\n",
    "# Download the images\n",
    "for i, row in df.iterrows():\n",
    "    download_image(row['Icon URL'], f'icons/{i}.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Extract features from the icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:52:48.299695Z",
     "start_time": "2023-04-14T10:52:13.578629Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_icon(img_path):\n",
    "    # Load the game icon image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (100, 100))\n",
    "\n",
    "    # Extract color features using color histograms\n",
    "    colors = ('b', 'g', 'r')\n",
    "    color_features = []\n",
    "    for k, col in enumerate(colors):\n",
    "        hist = cv2.calcHist([img], [k], None, [256], [0, 256])\n",
    "        color_features.append(hist)\n",
    "\n",
    "    # Reshape the color features to have a single dimension\n",
    "    color_features = np.concatenate(color_features).ravel()\n",
    "\n",
    "    # Extract shape features using edge detection\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    edge_features = np.array(edges).flatten()\n",
    "\n",
    "    # Combine the color and shape features into a single feature vector\n",
    "    feature_vector = np.concatenate((color_features, edge_features))\n",
    "\n",
    "    # Normalize the feature vector to have unit length\n",
    "    normalized_feature_vector = feature_vector / np.linalg.norm(feature_vector)\n",
    "\n",
    "    return normalized_feature_vector\n",
    "\n",
    "# Create a list to store the feature vectors\n",
    "icon_features = []\n",
    "\n",
    "# Iterate over the images and extract the features\n",
    "for i, row in df.iterrows():\n",
    "    icon_features.append(preprocess_icon(f'icons/{i}.png'))\n",
    "\n",
    "# Apply PCA to reduce the number of features\n",
    "pca = PCA(n_components=10)\n",
    "icon_features_pca = pca.fit_transform(icon_features)\n",
    "\n",
    "icon_features_df = pd.DataFrame(icon_features_pca, columns=[f'icon_{i}' for i in range(icon_features_pca.shape[1])])\n",
    "icon_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Add the icon features to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:53:05.530442Z",
     "start_time": "2023-04-14T10:53:04.975260Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concatenate the icon features with the other features\n",
    "df = pd.concat([df, icon_features_df], axis=1)\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv('games_with_icon_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:53:31.380503Z",
     "start_time": "2023-04-14T10:53:31.354875Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T14:42:19.976831Z",
     "start_time": "2023-04-14T14:42:19.786259Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  5  6 10 28 29 36 41 52 56]\n",
      "Index(['Developer', 'Original Release Date', 'Current Version Release Date',\n",
      "       'Genre_PCA_3', 'Highest Purchase', 'Average Purchase',\n",
      "       'Description_PCA_6', 'Subtitle_PCA_1', 'Name_PCA_2', 'Name_PCA_6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('games_with_icon_features.csv')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "y = df['Average User Rating']\n",
    "features = df.drop(['Average User Rating'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "X = selector.fit_transform(features, y)\n",
    "\n",
    "# print the selected features\n",
    "print(selector.get_support(indices=True))\n",
    "seleted_features = features.columns[selector.get_support(indices=True)]\n",
    "print(seleted_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T14:40:09.683179Z",
     "start_time": "2023-04-14T14:40:09.629559Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.49\n",
      "Coefficient of determination: 0.15\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# print the features weights\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39mcoef_)):\n\u001b[1;32m---> 20\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39mcolumns[i]\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mcoef_[i]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "import pickle\n",
    "pickle.dump(model, open('models/LR_model.pkl', 'wb'))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "# print the features weights\n",
    "for i in range(len(model.coef_)):\n",
    "    print(f'Feature {selected_features[i]}: {model.coef_[i]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T11:00:32.712100Z",
     "start_time": "2023-04-14T11:00:32.642347Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a ridge regression model\n",
    "model = Ridge(alpha=0.5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(model, open('models/Ridge_model.pkl', 'wb'))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T11:00:35.138470Z",
     "start_time": "2023-04-14T11:00:35.102309Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a lasso regression model\n",
    "model = Lasso(alpha=0.5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(model, open('models/Lasso_model.pkl', 'wb'))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T11:00:37.282470Z",
     "start_time": "2023-04-14T11:00:37.226872Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an elastic net regression model\n",
    "model = ElasticNet(alpha=0.5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(model, open('models/ElasticNet_model.pkl', 'wb'))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T11:02:11.403793Z",
     "start_time": "2023-04-14T11:00:55.155863Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a polynomial regression model\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(model, open('models/Polynomial_model.pkl', 'wb'))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
