{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T14:19:38.839351Z",
     "start_time": "2023-04-14T14:19:38.815268Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:33:46.390000Z",
     "start_time": "2023-04-14T10:33:46.279076Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_origin = pd.read_csv('games-regression-dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df, df_test = train_test_split(df_origin, test_size=0.2, random_state=42)\n",
    "df_test.to_csv('df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:07.218975Z",
     "start_time": "2023-04-14T10:35:07.199405Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop Primary Genre\n",
    "df.drop(['Primary Genre', 'ID', 'URL'], axis=1, inplace=True)\n",
    "\n",
    "df['Original Release Date'] = pd.to_datetime(df['Original Release Date'], errors='coerce', format='%d/%m/%Y')\n",
    "df['Current Version Release Date'] = pd.to_datetime(df['Current Version Release Date'], errors='coerce', format='%d/%m/%Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T16:07:00.183708Z",
     "start_time": "2023-04-13T16:07:00.127616Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:05.138536Z",
     "start_time": "2023-04-13T14:33:05.138536Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:07.893814Z",
     "start_time": "2023-04-13T14:33:07.893814Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                               0\n",
       "Subtitle                        3027\n",
       "Icon URL                           0\n",
       "User Rating Count                  0\n",
       "Price                              0\n",
       "In-app Purchases                1608\n",
       "Description                        0\n",
       "Developer                          0\n",
       "Age Rating                         0\n",
       "Languages                          6\n",
       "Size                               0\n",
       "Genres                             0\n",
       "Original Release Date              0\n",
       "Current Version Release Date       0\n",
       "Average User Rating                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:21.139604Z",
     "start_time": "2023-04-13T14:33:21.139604Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Genres'] = df['Genres'].astype(str)\n",
    "df['Genres'] = df['Genres'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "genre_counts = df.explode('Genres').groupby('Genres').size().sort_values(ascending=False)\n",
    "genre_counts\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:43.637371Z",
     "start_time": "2023-04-13T14:33:43.637371Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Developer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:47.598084Z",
     "start_time": "2023-04-13T14:33:47.598084Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Developer'].unique().size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T14:33:49.943309Z",
     "start_time": "2023-04-13T14:33:49.943309Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Languages'] = df['Languages'].astype(str)\n",
    "\n",
    "df['Languages'] = df['Languages'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "langs_counts = df.explode('Languages').groupby('Languages').size().sort_values(ascending=False)\n",
    "print(langs_counts[1:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Developer preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:14.110217Z",
     "start_time": "2023-04-14T10:35:13.123201Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "df['Developer'] = df['Developer'].astype(str)\n",
    "df['Developer'] = df['Developer'].str.replace(\"'\", \"\").str.strip('[]')\n",
    "\n",
    "# Replace the developer names with less than 3 games with 'Other'\n",
    "dev_counts = df['Developer'].value_counts()\n",
    "other = dev_counts[dev_counts < 3].index\n",
    "df['Developer'] = df['Developer'].replace(other, 'Other')\n",
    "\n",
    "dev_df = df[['Developer', 'Average User Rating']].groupby('Developer').mean()\n",
    "\n",
    "# Save dev_df to be used on the test set\n",
    "dev_df.to_csv('encoders/dev_df.csv')\n",
    "\n",
    "# Replace the developer names with the average user rating from dev_df\n",
    "df['Developer'] = df['Developer'].replace(dev_df.index, dev_df['Average User Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Genres preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. NLP approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:21.245168Z",
     "start_time": "2023-04-14T10:35:20.885068Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the genres column to a list of strings\n",
    "df['Genres'] = df['Genres'].astype(str)\n",
    "df['Genres'] = df['Genres'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# drop Games, Strategy, Entertainment from the Genres column\n",
    "df['Genres'] = df['Genres'].apply(lambda x: [genre for genre in x if genre not in ['Games', 'Strategy', 'Entertainment']])\n",
    "\n",
    "# Join the list of genres into a single string\n",
    "genres = df['Genres'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Create a count Vectorizer and fit it to the genres\n",
    "count_vec = CountVectorizer()\n",
    "bow_genres = count_vec.fit_transform(genres)\n",
    "\n",
    "# Apply principal component analysis to reduce the dimensionality\n",
    "pca = PCA(n_components=10)\n",
    "pca_genres = pca.fit_transform(bow_genres.toarray())\n",
    "\n",
    "# Add the PCA-transformed genres to the original dataframe\n",
    "for i in range(len(pca_genres[0])):\n",
    "    df[f'Genre_PCA_{i}'] = pca_genres[:, i]\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Genres'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dummy variables approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the genres column to a list of strings\n",
    "df['Genres'] = df['Genres'].astype(str)\n",
    "df['Genres'] = df['Genres'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# drop Games, Strategy, Entertainment from the Genres column\n",
    "df['Genres'] = df['Genres'].apply(lambda x: [genre for genre in x if genre not in ['Games', 'Strategy', 'Entertainment']])\n",
    "\n",
    "# Replace genres with counts less than 100 with 'infrequent' as it would represent a very small percentage of the data (less than 2%)\n",
    "other = df['Genres'].explode().value_counts()[df['Genres'].explode().value_counts() < 100].index\n",
    "df['Genres'] = df['Genres'].apply(lambda x: [genre if genre not in other else 'infrequent' for genre in x])\n",
    "\n",
    "# Replace empty lists with 'infrequent'\n",
    "df['Genres'] = df['Genres'].apply(lambda x: ['infrequent'] if len(x) == 0 else x)\n",
    "\n",
    "# Get dummy variables for the genres\n",
    "genres = pd.get_dummies(df['Genres'].apply(pd.Series).stack()).sum(level=0)\n",
    "\n",
    "# Add the dummy variables to the original dataframe\n",
    "df = pd.concat([df, genres], axis=1)\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Genres'], axis=1)\n",
    "\n",
    "df.iloc[:, 15:].head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multi-label binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4988, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Board</th>\n",
       "      <th>Card</th>\n",
       "      <th>Casual</th>\n",
       "      <th>Education</th>\n",
       "      <th>Family</th>\n",
       "      <th>Puzzle</th>\n",
       "      <th>Role Playing</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>Sports</th>\n",
       "      <th>infrequent_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Adventure  Board  Card  Casual  Education  Family  Puzzle  Role Playing  \\\n",
       "2173        0.0    0.0   0.0     0.0        0.0     0.0     0.0           0.0   \n",
       "927         0.0    0.0   0.0     0.0        0.0     0.0     1.0           0.0   \n",
       "2499        0.0    0.0   0.0     0.0        0.0     0.0     0.0           0.0   \n",
       "45          0.0    0.0   0.0     0.0        0.0     0.0     0.0           0.0   \n",
       "1741        0.0    0.0   0.0     0.0        0.0     0.0     0.0           1.0   \n",
       "\n",
       "      Simulation  Sports  infrequent_genre  \n",
       "2173         0.0     0.0               1.0  \n",
       "927          0.0     0.0               0.0  \n",
       "2499         0.0     0.0               1.0  \n",
       "45           0.0     0.0               0.0  \n",
       "1741         0.0     0.0               0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the genres column to a list of strings\n",
    "df['Genres'] = df['Genres'].astype(str)\n",
    "df['Genres'] = df['Genres'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# drop Games, Strategy, Entertainment from the Genres column\n",
    "df['Genres'] = df['Genres'].apply(lambda x: [genre for genre in x if genre not in ['Games', 'Strategy', 'Entertainment']])\n",
    "\n",
    "# Replace genres with counts less than 100 with 'infrequent' as it would represent a very small percentage of the data (less than 2%)\n",
    "other = df['Genres'].explode().value_counts()[df['Genres'].explode().value_counts() < 100].index\n",
    "df['Genres'] = df['Genres'].apply(lambda x: [genre if genre not in other else 'infrequent_genre' for genre in x])\n",
    "\n",
    "# Instantiate the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit the MultiLabelBinarizer to the genres\n",
    "mlb.fit(df['Genres'])\n",
    "\n",
    "# Drop nan from the classes\n",
    "mlb.classes_ = np.delete(mlb.classes_, np.where(mlb.classes_ == 'nan'))\n",
    "\n",
    "# Save the mlb for later use with the test data\n",
    "pickle.dump(mlb, open('encoders/mlb_genres.pkl', 'wb'))\n",
    "\n",
    "# Transform the genres into a one-hot encoded array\n",
    "genres_mlb = mlb.transform(df['Genres'])\n",
    "\n",
    "# Create a dataframe from the one-hot encoded array\n",
    "genres_mlb_df = pd.DataFrame(genres_mlb, columns=mlb.classes_)\n",
    "\n",
    "# Add the one-hot encoded genres to the original dataframe\n",
    "df = pd.concat([df, genres_mlb_df], axis=1)\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Genres'], axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.iloc[:, 15:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Languages preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. NLP approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:38.695352Z",
     "start_time": "2023-04-14T10:35:38.599717Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the langs column to a list of strings\n",
    "df['Languages'] = df['Languages'].astype(str)\n",
    "df['Languages'] = df['Languages'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# Drop the English language from the Languages column\n",
    "df['Languages'] = df['Languages'].apply(lambda x: [lang for lang in x if lang not in ['EN']])\n",
    "\n",
    "# Join the list of langs into a single string\n",
    "languages = df['Languages'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Create a count Vectorizer and fit it to the langs\n",
    "count_vec = CountVectorizer()\n",
    "bow_languages = count_vec.fit_transform(languages)\n",
    "\n",
    "# Apply principal component analysis to reduce the dimensionality\n",
    "pca = PCA(n_components=10)\n",
    "pca_languages = pca.fit_transform(bow_languages.toarray())\n",
    "\n",
    "# Add the PCA-transformed langs to the original dataframe\n",
    "for i in range(len(pca_languages[0])):\n",
    "    df[f'Languages_PCA_{i}'] = pca_languages[:, i]\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Languages'], axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.iloc[:, 15:].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dummy variables approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the langs column to a list of strings\n",
    "df['Languages'] = df['Languages'].astype(str)\n",
    "df['Languages'] = df['Languages'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# Create a column with the number of languages supported\n",
    "df['langs_count'] = df['Languages'].apply(lambda x: len(x))\n",
    "\n",
    "# Drop the English language from the Languages column (it is the most common language and would dominate the model)\n",
    "df['Languages'] = df['Languages'].apply(lambda x: [lang for lang in x if lang not in ['EN']])\n",
    "\n",
    "# Replace langs with counts less than 500 with 'infrequent_langs' as it would represent a very small percentage of the data (less than 10%)\n",
    "other = df['Languages'].explode().value_counts()[df['Languages'].explode().value_counts() < 500].index\n",
    "df['Languages'] = df['Languages'].apply(lambda x: [lang if lang not in other else 'infrequent_langs' for lang in x])\n",
    "\n",
    "# Replace empty lists with 'infrequent'\n",
    "df['Languages'] = df['Languages'].apply(lambda x: ['infrequent_langs'] if len(x) == 0 else x)\n",
    "\n",
    "# Get dummy variables for the langs\n",
    "langs = pd.get_dummies(df['Languages'].apply(pd.Series).stack()).sum(level=0)\n",
    "\n",
    "# Add the dummy variables to the original dataframe\n",
    "df = pd.concat([df, langs], axis=1)\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Languages'], axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.iloc[:, 15:].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multi-label binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5166, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Board</th>\n",
       "      <th>Card</th>\n",
       "      <th>Casual</th>\n",
       "      <th>Education</th>\n",
       "      <th>Family</th>\n",
       "      <th>Puzzle</th>\n",
       "      <th>Role Playing</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>Sports</th>\n",
       "      <th>infrequent_genre</th>\n",
       "      <th>...</th>\n",
       "      <th>DE</th>\n",
       "      <th>ES</th>\n",
       "      <th>FR</th>\n",
       "      <th>IT</th>\n",
       "      <th>JA</th>\n",
       "      <th>KO</th>\n",
       "      <th>PT</th>\n",
       "      <th>RU</th>\n",
       "      <th>ZH</th>\n",
       "      <th>infrequent_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Board  Card  Casual  Education  Family  Puzzle  Role Playing  \\\n",
       "2173    0.0   0.0     0.0        0.0     0.0     0.0           0.0   \n",
       "927     0.0   0.0     0.0        0.0     0.0     1.0           0.0   \n",
       "2499    0.0   0.0     0.0        0.0     0.0     0.0           0.0   \n",
       "45      0.0   0.0     0.0        0.0     0.0     0.0           0.0   \n",
       "1741    0.0   0.0     0.0        0.0     0.0     0.0           1.0   \n",
       "\n",
       "      Simulation  Sports  infrequent_genre  ...   DE   ES   FR   IT   JA   KO  \\\n",
       "2173         0.0     0.0               1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "927          0.0     0.0               0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2499         0.0     0.0               1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "45           0.0     0.0               0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1741         0.0     0.0               0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       PT   RU   ZH  infrequent_lang  \n",
       "2173  0.0  0.0  1.0              0.0  \n",
       "927   0.0  0.0  0.0              0.0  \n",
       "2499  0.0  0.0  0.0              0.0  \n",
       "45    0.0  0.0  0.0              0.0  \n",
       "1741  0.0  0.0  0.0              0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Convert the langs column to a list of strings\n",
    "df['Languages'] = df['Languages'].astype(str)\n",
    "df['Languages'] = df['Languages'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")\n",
    "\n",
    "# Create a column with the number of languages supported\n",
    "df['langs_count'] = df['Languages'].apply(lambda x: len(x))\n",
    "\n",
    "# Drop the English language from the Languages column (it is the most common language and would dominate the model)\n",
    "df['Languages'] = df['Languages'].apply(lambda x: [lang for lang in x if lang not in ['EN']])\n",
    "\n",
    "# Replace langs with counts less than 500 with 'infrequent_langs' as it would represent a very small percentage of the data (less than 10%)\n",
    "other = df['Languages'].explode().value_counts()[df['Languages'].explode().value_counts() < 400].index\n",
    "df['Languages'] = df['Languages'].apply(lambda x: [lang if lang not in other else 'infrequent_lang' for lang in x])\n",
    "\n",
    "# Instantiate the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit the MultiLabelBinarizer to the langs\n",
    "mlb.fit(df['Languages'])\n",
    "\n",
    "# Drop nan from the classes\n",
    "mlb.classes_ = np.delete(mlb.classes_, np.where(mlb.classes_ == 'nan'))\n",
    "\n",
    "# Save the mlb for later use with the test data\n",
    "pickle.dump(mlb, open('encoders/mlb_langs.pkl', 'wb'))\n",
    "\n",
    "# Transform the langs into a one-hot encoded array\n",
    "langs_mlb = mlb.transform(df['Languages'])\n",
    "\n",
    "# Create a dataframe from the one-hot encoded array\n",
    "langs_mlb_df = pd.DataFrame(langs_mlb, columns=mlb.classes_)\n",
    "\n",
    "# Add the encoded langs to the original dataframe\n",
    "df = pd.concat([df, langs_mlb_df], axis=1)\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(['Languages'], axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.iloc[:, 15:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## In-app Purchases preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:52.935497Z",
     "start_time": "2023-04-14T10:35:52.881403Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Free apps might skew the in-app purchases column,\n",
    "# so we might split the dataset into free and paid apps\n",
    "\n",
    "df['In-app Purchases'] = df['In-app Purchases'].astype(str)\n",
    "df['In-app Purchases'] = df['In-app Purchases'].str.strip('[]').str.replace(\"'\", \"\").str.split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:35:54.565885Z",
     "start_time": "2023-04-14T10:35:54.456681Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to float\n",
    "df['In-app Purchases'] = df['In-app Purchases'].apply(lambda x: [float(i) for i in x])\n",
    "\n",
    "# Get the number of in-app purchases\n",
    "df['purchases_count'] = df['In-app Purchases'].apply(lambda x: len(x))\n",
    "\n",
    "# Get the lowest, highest and average purchase\n",
    "df['lowest_purchase'] = df['In-app Purchases'].apply(lambda x: min(x) if len(x) > 0 else 0)\n",
    "df['highest_purchase'] = df['In-app Purchases'].apply(lambda x: max(x) if len(x) > 0 else 0)\n",
    "df['average_purchase'] = df['In-app Purchases'].apply(lambda x: np.mean(x) if len(x) > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:36:00.624093Z",
     "start_time": "2023-04-14T10:36:00.576764Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Icon URL</th>\n",
       "      <th>User Rating Count</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Age Rating</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Size</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Original Release Date</th>\n",
       "      <th>Current Version Release Date</th>\n",
       "      <th>Average User Rating</th>\n",
       "      <th>purchases_count</th>\n",
       "      <th>lowest_purchase</th>\n",
       "      <th>highest_purchase</th>\n",
       "      <th>average_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>Digfender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://is2-ssl.mzstatic.com/image/thumb/Purpl...</td>\n",
       "      <td>348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Digfender is easily one of the best tower def...</td>\n",
       "      <td>Mugshot Games Pty Ltd</td>\n",
       "      <td>9.0</td>\n",
       "      <td>EN</td>\n",
       "      <td>479550464</td>\n",
       "      <td>Games, Strategy, Puzzle</td>\n",
       "      <td>735920</td>\n",
       "      <td>736359</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.99</td>\n",
       "      <td>19.99</td>\n",
       "      <td>6.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>TowerMadness Zero</td>\n",
       "      <td>Classic Defense Strategy</td>\n",
       "      <td>https://is5-ssl.mzstatic.com/image/thumb/Purpl...</td>\n",
       "      <td>95466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Addictive, time-sucking fun. There are plenty...</td>\n",
       "      <td>Limbic Software</td>\n",
       "      <td>9.0</td>\n",
       "      <td>EN, DE</td>\n",
       "      <td>58547200</td>\n",
       "      <td>Games, Puzzle, Strategy</td>\n",
       "      <td>733705</td>\n",
       "      <td>736758</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.99</td>\n",
       "      <td>5.99</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Free Gems Guide Calculator for Clash Of Clans ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://is5-ssl.mzstatic.com/image/thumb/Purpl...</td>\n",
       "      <td>822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Welcome to your new favorite Clash of Clans Ca...</td>\n",
       "      <td>Tu Anh Do</td>\n",
       "      <td>17.0</td>\n",
       "      <td>EN</td>\n",
       "      <td>22884352</td>\n",
       "      <td>Games, Utilities, Strategy, Casual</td>\n",
       "      <td>735558</td>\n",
       "      <td>735977</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Memory Sequence - Brain Game</td>\n",
       "      <td>Bounce, Bounce, Bounce</td>\n",
       "      <td>https://is1-ssl.mzstatic.com/image/thumb/Purpl...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Bounce, Bounce, Bounce your way past each obs...</td>\n",
       "      <td>OSUAPP LTD</td>\n",
       "      <td>4.0</td>\n",
       "      <td>EN</td>\n",
       "      <td>164545536</td>\n",
       "      <td>Games, Strategy, Casual, Education</td>\n",
       "      <td>736684</td>\n",
       "      <td>737228</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>NEO Scavenger</td>\n",
       "      <td>Post-apocalyptic survival RPG</td>\n",
       "      <td>https://is3-ssl.mzstatic.com/image/thumb/Purpl...</td>\n",
       "      <td>147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Play the acclaimed PC survival RPG on your tab...</td>\n",
       "      <td>Blue Bottle Games, LLC</td>\n",
       "      <td>17.0</td>\n",
       "      <td>EN</td>\n",
       "      <td>117317632</td>\n",
       "      <td>Games, Entertainment, Role Playing, Strategy</td>\n",
       "      <td>736536</td>\n",
       "      <td>736661</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.99</td>\n",
       "      <td>9.99</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name  \\\n",
       "2173                                          Digfender   \n",
       "927                                   TowerMadness Zero   \n",
       "2499  Free Gems Guide Calculator for Clash Of Clans ...   \n",
       "45                         Memory Sequence - Brain Game   \n",
       "1741                                      NEO Scavenger   \n",
       "\n",
       "                           Subtitle  \\\n",
       "2173                            NaN   \n",
       "927        Classic Defense Strategy   \n",
       "2499                            NaN   \n",
       "45           Bounce, Bounce, Bounce   \n",
       "1741  Post-apocalyptic survival RPG   \n",
       "\n",
       "                                               Icon URL  User Rating Count  \\\n",
       "2173  https://is2-ssl.mzstatic.com/image/thumb/Purpl...                348   \n",
       "927   https://is5-ssl.mzstatic.com/image/thumb/Purpl...              95466   \n",
       "2499  https://is5-ssl.mzstatic.com/image/thumb/Purpl...                822   \n",
       "45    https://is1-ssl.mzstatic.com/image/thumb/Purpl...                 14   \n",
       "1741  https://is3-ssl.mzstatic.com/image/thumb/Purpl...                147   \n",
       "\n",
       "      Price                                        Description  \\\n",
       "2173    0.0  \"Digfender is easily one of the best tower def...   \n",
       "927     0.0  \"Addictive, time-sucking fun. There are plenty...   \n",
       "2499    0.0  Welcome to your new favorite Clash of Clans Ca...   \n",
       "45      0.0  \"Bounce, Bounce, Bounce your way past each obs...   \n",
       "1741    0.0  Play the acclaimed PC survival RPG on your tab...   \n",
       "\n",
       "                   Developer  Age Rating Languages       Size  \\\n",
       "2173   Mugshot Games Pty Ltd         9.0        EN  479550464   \n",
       "927          Limbic Software         9.0    EN, DE   58547200   \n",
       "2499               Tu Anh Do        17.0        EN   22884352   \n",
       "45                OSUAPP LTD         4.0        EN  164545536   \n",
       "1741  Blue Bottle Games, LLC        17.0        EN  117317632   \n",
       "\n",
       "                                            Genres  Original Release Date  \\\n",
       "2173                       Games, Strategy, Puzzle                 735920   \n",
       "927                        Games, Puzzle, Strategy                 733705   \n",
       "2499            Games, Utilities, Strategy, Casual                 735558   \n",
       "45              Games, Strategy, Casual, Education                 736684   \n",
       "1741  Games, Entertainment, Role Playing, Strategy                 736536   \n",
       "\n",
       "      Current Version Release Date  Average User Rating  purchases_count  \\\n",
       "2173                        736359                  5.0               10   \n",
       "927                         736758                  4.0               10   \n",
       "2499                        735977                  3.5                1   \n",
       "45                          737228                  4.5                2   \n",
       "1741                        736661                  4.0                1   \n",
       "\n",
       "      lowest_purchase  highest_purchase  average_purchase  \n",
       "2173             1.99             19.99              6.69  \n",
       "927              1.99              5.99              2.49  \n",
       "2499             0.00              0.00              0.00  \n",
       "45               2.99              2.99              2.99  \n",
       "1741             9.99              9.99              9.99  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the original column\n",
    "df = df.drop(['In-app Purchases'], axis=1)\n",
    "\n",
    "df['lowest_purchase'] = df['lowest_purchase'].fillna(0)\n",
    "df['highest_purchase'] = df['highest_purchase'].fillna(0)\n",
    "df['average_purchase'] = df['average_purchase'].fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Age Rating preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:36:03.614263Z",
     "start_time": "2023-04-14T10:36:03.579637Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "df['Age Rating'] = df['Age Rating'].astype(str)\n",
    "\n",
    "# Remove the + sign\n",
    "df['Age Rating'] = df['Age Rating'].str.replace('+', '')\n",
    "\n",
    "# Convert to int\n",
    "df['Age Rating'] = df['Age Rating'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dates preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:36:05.737187Z",
     "start_time": "2023-04-14T10:36:05.699973Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the datetime to ordinal\n",
    "df['Original Release Date'] = df['Original Release Date'].apply(lambda x: x.toordinal())\n",
    "df['Current Version Release Date'] = df['Current Version Release Date'].apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:43:13.386866Z",
     "start_time": "2023-04-14T10:43:13.386866Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def preprocess_nlp(col):\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "    # Remove URLs and email addresses\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'http\\S+|www.\\S+|\\S+@\\S+', '', x))\n",
    "\n",
    "    # Remove the punctuation, numbers, and convert to lowercase\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(re.findall(r'\\w+', x.lower())))\n",
    "\n",
    "    # Remove the stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "    # Stemming\n",
    "    st = nltk.PorterStemmer()\n",
    "    df[col] = df[col].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "\n",
    "    # Lemmatization\n",
    "    lem = nltk.WordNetLemmatizer()\n",
    "    df[col] = df[col].apply(lambda x: \" \".join([lem.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "    # Remove the frequent and rare words\n",
    "    freq = pd.Series(' '.join(df[col]).split()).value_counts()\n",
    "    common_freq = list(freq[:10].index)\n",
    "    rare_freq = list(freq[-10:].index)\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x for x in x.split() if x not in common_freq+rare_freq))\n",
    "\n",
    "    # Remove the whitespaces\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x.strip() for x in x.split()))\n",
    "\n",
    "    # Replace NaN values with empty string\n",
    "    df[col] = df[col].fillna('')\n",
    "\n",
    "    # Convert text data to bag-of-words representation\n",
    "    vectorizer = CountVectorizer()\n",
    "    BoW = vectorizer.fit_transform(df[col])\n",
    "\n",
    "    # Apply principal component analysis to reduce the dimensionality\n",
    "    pca_ = PCA(n_components=10)\n",
    "    pca_col = pca_.fit_transform(BoW.toarray())\n",
    "\n",
    "    # Add the PCA-transformed col to the original dataframe\n",
    "    for feat in range(10):\n",
    "        df[f'{col}_PCA_{feat}'] = pca_col[:, feat]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:43:49.505557Z",
     "start_time": "2023-04-14T10:43:49.505557Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_nlp('Description')\n",
    "preprocess_nlp('Subtitle')\n",
    "preprocess_nlp('Name')\n",
    "\n",
    "df = df.drop(['Description', 'Subtitle', 'Name'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Icon preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Download the icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T15:23:14.248477Z",
     "start_time": "2023-04-13T15:23:14.247478Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "df['Icon URL'] = df['Icon URL'].astype(str)\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "def download_image(url, filename):\n",
    "    r = requests.get(url, stream=True)\n",
    "    if r.status_code == 200:\n",
    "        with open(filename, 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "\n",
    "# Create a folder to store the images\n",
    "if not os.path.exists('icons'):\n",
    "    os.makedirs('icons')\n",
    "\n",
    "# Download the images\n",
    "for i, row in df.iterrows():\n",
    "    download_image(row['Icon URL'], f'icons/{i}.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the URL with the icon filename which is the index of the row\n",
    "df['Icon URL'] = df.apply(lambda row : f'icons/{row.name}.png', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Extract features from the icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:52:48.299695Z",
     "start_time": "2023-04-14T10:52:13.578629Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess_icon(img_path):\n",
    "    # Load the game icon image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (100, 100))\n",
    "\n",
    "    # Extract color features using color histograms\n",
    "    colors = ('b', 'g', 'r')\n",
    "    color_features = []\n",
    "    for k, col in enumerate(colors):\n",
    "        hist = cv2.calcHist([img], [k], None, [256], [0, 256])\n",
    "        color_features.append(hist)\n",
    "\n",
    "    # Reshape the color features to have a single dimension\n",
    "    color_features = np.concatenate(color_features).ravel()\n",
    "\n",
    "    # Extract shape features using edge detection\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    edge_features = np.array(edges).flatten()\n",
    "\n",
    "    # Combine the color and shape features into a single feature vector\n",
    "    feature_vector = np.concatenate((color_features, edge_features))\n",
    "\n",
    "    # Normalize the feature vector to have unit length\n",
    "    normalized_feature_vector = feature_vector / np.linalg.norm(feature_vector)\n",
    "\n",
    "    return normalized_feature_vector\n",
    "\n",
    "# Create a list to store the feature vectors\n",
    "icon_features = []\n",
    "\n",
    "# Iterate over the images and extract the features\n",
    "for i, row in df.iterrows():\n",
    "    icon_features.append(preprocess_icon(row['Icon URL']))\n",
    "    \n",
    "# Apply PCA to reduce the number of features\n",
    "pca = PCA(n_components=10)\n",
    "icon_features_pca = pca.fit_transform(icon_features)\n",
    "\n",
    "icon_features_df = pd.DataFrame(icon_features_pca, columns=[f'icon_{i}' for i in range(icon_features_pca.shape[1])])\n",
    "icon_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Add the icon features to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:53:05.530442Z",
     "start_time": "2023-04-14T10:53:04.975260Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concatenate the icon features with the other features\n",
    "df = pd.concat([df, icon_features_df], axis=1)\n",
    "\n",
    "# Drop the icon URL column\n",
    "df = df.drop(['Icon URL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T10:53:31.380503Z",
     "start_time": "2023-04-14T10:53:31.354875Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_train.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Save the scaler\n",
    "pickle.dump(scaler, open('scalers/std_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Save the scaler\n",
    "pickle.dump(scaler, open('scalers/min_max_scaler.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "X = selector.fit_transform(features, y)\n",
    "\n",
    "# print the selected features\n",
    "print(selector.get_support(indices=True))\n",
    "seleted_features = features.columns[selector.get_support(indices=True)]\n",
    "print(seleted_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T14:40:09.683179Z",
     "start_time": "2023-04-14T14:40:09.629559Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(model, open('models/LR_model.pkl', 'wb'))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "# print the features weights\n",
    "for i in range(len(model.coef_)):\n",
    "    print(f'Feature {selected_features[i]}: {model.coef_[i]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T11:00:32.712100Z",
     "start_time": "2023-04-14T11:00:32.642347Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a ridge regression model\n",
    "model = Ridge(alpha=0.5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(model, open('models/Ridge_model.pkl', 'wb'))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T11:00:35.138470Z",
     "start_time": "2023-04-14T11:00:35.102309Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a lasso regression model\n",
    "model = Lasso(alpha=0.5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(model, open('models/Lasso_model.pkl', 'wb'))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T11:00:37.282470Z",
     "start_time": "2023-04-14T11:00:37.226872Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an elastic net regression model\n",
    "model = ElasticNet(alpha=0.5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(model, open('models/ElasticNet_model.pkl', 'wb'))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T11:02:11.403793Z",
     "start_time": "2023-04-14T11:00:55.155863Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a polynomial regression model\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(model, open('models/Polynomial_model.pkl', 'wb'))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
